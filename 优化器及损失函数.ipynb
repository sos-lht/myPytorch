{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PyTorch中的优化器\n",
    "- 在深度学习领域，优化算法的选择也是一个模型的重中之重即使在数据集和模型架构完全相同的情况下，采用不同的优化算法，也很可能导致截然不同的训练效果。\n",
    "- PyTorch中的torch.optim是一个实现了各种优化算法的库。大部分常用的方法得到支持，并且接口具备足够的通用性，使得未来能够集成更加复杂的方法。\n",
    "### 1、构建优化器：  \n",
    "`optimizer = optim.SGD(model.parameters(),lr=0.01,momentum=0.9)`  \n",
    "`optimizer = optim.Adam([var1, var2], lr = 0.0001)`\n",
    "### 2、参数设置：  \n",
    "```\n",
    "optim.SGD(\n",
    "    [\n",
    "        {'params': model.base.parameters()},\n",
    "        {'params': model.classifier.parameters(), 'lr': 1e-3}\n",
    "    ], lr=1e-2, momentum=0.9)\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net(\n",
      "  (block): Sequential(\n",
      "    (conv1): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (relu_1): ReLU()\n",
      "  )\n",
      "  (module): Sequential(\n",
      "    (conv2): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (relu_2): ReLU()\n",
      "  )\n",
      ")\n",
      "<generator object Module.parameters at 0x7fbc499c75f0>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SGD (\n",
       "Parameter Group 0\n",
       "    dampening: 0\n",
       "    differentiable: False\n",
       "    foreach: None\n",
       "    lr: 0.01\n",
       "    maximize: False\n",
       "    momentum: 0.9\n",
       "    nesterov: False\n",
       "    weight_decay: 0\n",
       "\n",
       "Parameter Group 1\n",
       "    dampening: 0\n",
       "    differentiable: False\n",
       "    foreach: None\n",
       "    lr: 0.001\n",
       "    maximize: False\n",
       "    momentum: 0.9\n",
       "    nesterov: False\n",
       "    weight_decay: 0\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "from collections import OrderedDict\n",
    "import torch.optim as optim\n",
    "\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self) -> None:\n",
    "        super(Net,self).__init__()\n",
    "        self.block = nn.Sequential(\n",
    "            OrderedDict(\n",
    "                [\n",
    "                    (\"conv1\",nn.Conv2d(3,32,3,1,1)),\n",
    "                    (\"relu_1\",nn.ReLU())\n",
    "                ]\n",
    "            )\n",
    "        )\n",
    "        self.module = nn.Sequential(\n",
    "            OrderedDict(\n",
    "                [\n",
    "                    (\"conv2\",nn.Conv2d(3,32,3,1,1)),\n",
    "                    (\"relu_2\",nn.ReLU())\n",
    "                ]\n",
    "            )\n",
    "        )\n",
    "\n",
    "    def forward(self,x):\n",
    "        x = self.block(x)\n",
    "        return x\n",
    "\n",
    "model = Net()\n",
    "print(model)\n",
    "print(model.parameters())\n",
    "\n",
    "optimizer = optim.SGD(model.parameters(), lr = 0.01, momentum=0.9)\n",
    "\n",
    "optim.SGD(\n",
    "    [\n",
    "        {'params': model.block.parameters()},\n",
    "        {'params': model.module.parameters(), 'lr': 1e-3}\n",
    "    ], lr=1e-2, momentum=0.9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3、优化器更新：三个步骤\n",
    "- #### 优化器清零\n",
    "- #### 损失计算及反向传播\n",
    "- #### 优化器更新"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n# 循环\\nfor input, target in dataset:\\n    #优化器清零\\n    optimizer.zero_grad()\\n    #输出结果\\n    output = model(input)\\n    #计算损失\\n    loss = loss_fn(output, target)\\n    #反向传播\\n    loss.backward()\\n    #优化器更新\\n    optimizer.step()\\n'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "# 循环\n",
    "for input, target in dataset:\n",
    "    #优化器清零\n",
    "    optimizer.zero_grad()\n",
    "    #输出结果\n",
    "    output = model(input)\n",
    "    #计算损失\n",
    "    loss = loss_fn(output, target)\n",
    "    #反向传播\n",
    "    loss.backward()\n",
    "    #优化器更新\n",
    "    optimizer.step()\n",
    "\"\"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('env1')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "bc8c60f99e2e962c0e4a3e9c9f27c1bb5f2a586f6d03b97348d9b6648bd2cf92"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
