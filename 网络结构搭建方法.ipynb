{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 网络搭建\n",
    "### 四种方法：\n",
    "- 层层堆叠：利用torch.nn库中的各类层函数完成网络的构建，是最基本的构建方法。\n",
    "- Sequential: 该操作可以将各个层封装到Sequential构建的容器当中，更利于呈现复杂的网络结构。\n",
    "- Sequential+add_module(): 首先构建空的Sequential容器，然后利用add_module()函数一一添加相应的层。\n",
    "- Sequential+OrderedDict：对层结构命名的简单方法\n",
    "### 步骤：\n",
    "（1）class类的命名：要继承nn.Module的特征  \n",
    "（2）init部分：完成层的构建<u>（以上四种方法只有在该部分有区别）</u>  \n",
    "（3）forward部分：完成输入在神经网络中前向传播的过程  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net1(\n",
      "  (conv1): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (relu): ReLU()\n",
      "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (dense1): Linear(in_features=288, out_features=128, bias=True)\n",
      "  (dense2): Linear(in_features=128, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from collections import OrderedDict\n",
    "\n",
    "#方法一：层层堆叠:利用torch.nn逐一构建层结构\n",
    "class Net1(nn.Module):\n",
    "    def __init__(self) -> None:\n",
    "        super(Net1,self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3,32,3,1,1)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.pool = nn.MaxPool2d(2)\n",
    "        self.dense1 = nn.Linear(32 * 3 * 3, 128)\n",
    "        self.dense2 = nn.Linear(128,10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.pool(x)\n",
    "        x = x.view(x.size(0),-1)\n",
    "        x = self.dense1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.dense2(x)\n",
    "        # x = F.max_pool2d(F.relu(self.conv(x)),2)\n",
    "        # x = x.view(x.size(0),-1)\n",
    "        # x = F.relu(self.dense1(x))\n",
    "        # x = self.dense2(x)\n",
    "        return x\n",
    "net1 = Net1()\n",
    "print(net1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Note:  \n",
    "(1) 如果用torch.functional来构建层结构，在print时不会呈现出对应的结构。  \n",
    "(2) 如果采用层层堆叠的方式构建，print的结构只会按照实际命名的先后顺序出现，不代表实际的x的前向传播顺序。  \n",
    "(3) 利用Sequential构建的网络结构，基本上代表了前向传播的顺序（维度操作是不会出现在网络结构中的）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net2(\n",
      "  (conv): Sequential(\n",
      "    (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): ReLU()\n",
      "    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (dense): Sequential(\n",
      "    (0): Linear(in_features=288, out_features=128, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=128, out_features=10, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# 方法二：Sequential时序构建法，但是各层无名字，只有0，1，2代号\n",
    "class Net2(nn.Module):\n",
    "    def __init__(self) -> None:\n",
    "        super(Net2,self).__init__()\n",
    "        self.conv = nn.Sequential(\n",
    "            nn.Conv2d(3,32,3,1,1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2)\n",
    "        )\n",
    "        self.dense = nn.Sequential(\n",
    "            nn.Linear(32*3*3,128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128,10)\n",
    "        )\n",
    "    def forward(self,x):\n",
    "        conv_out = self.conv(x)\n",
    "        res = conv_out.view(conv_out.size(0),-1)\n",
    "        out = self.dense(res)\n",
    "        return out\n",
    "net2 = Net2()\n",
    "print(net2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net3(\n",
      "  (conv): Sequential(\n",
      "    (conv1): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (relu1): ReLU()\n",
      "    (pool1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (dense): Sequential(\n",
      "    (dense1): Linear(in_features=288, out_features=128, bias=True)\n",
      "    (relu2): ReLU()\n",
      "    (dense2): Linear(in_features=128, out_features=10, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# 方法三：Sequential + add_module()给容器中的各层赋予对应的名字\n",
    "class Net3(nn.Module):\n",
    "    def __init__(self) -> None:\n",
    "        super(Net3,self).__init__()\n",
    "        self.conv = nn.Sequential()\n",
    "        self.conv.add_module(\"conv1\",nn.Conv2d(3,32,3,1,1))\n",
    "        self.conv.add_module(\"relu1\",nn.ReLU())\n",
    "        self.conv.add_module(\"pool1\",nn.MaxPool2d(2))\n",
    "        self.dense = nn.Sequential()\n",
    "        self.dense.add_module(\"dense1\",nn.Linear(32*3*3,128))\n",
    "        self.dense.add_module(\"relu2\",nn.ReLU())\n",
    "        self.dense.add_module(\"dense2\",nn.Linear(128,10))\n",
    "    def forward(self,x):\n",
    "        conv_out2 = self.conv(x)\n",
    "        res = conv_out2.view(conv_out2.size(0),-1)\n",
    "        out = self.dense(res)\n",
    "        return out\n",
    "\n",
    "net3 = Net3()\n",
    "print(net3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net4(\n",
      "  (block): Sequential(\n",
      "    (conv1): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (relu_1): ReLU()\n",
      "    (pool1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (block2): Sequential(\n",
      "    (dense1): Linear(in_features=288, out_features=128, bias=True)\n",
      "    (relu_2): ReLU()\n",
      "    (dense2): Linear(in_features=128, out_features=10, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# 方法四：Sequential + OrderedDict 时序容器+有序字典的方式，对层结构和各自对应的的名字统一完成构建\n",
    "class Net4(nn.Module):\n",
    "    def __init__(self) -> None:\n",
    "        super(Net4,self).__init__()\n",
    "        self.block = nn.Sequential(\n",
    "            OrderedDict(\n",
    "                [\n",
    "                    (\"conv1\",nn.Conv2d(3,32,3,1,1)),\n",
    "                    (\"relu_1\",nn.ReLU()),\n",
    "                    (\"pool1\",nn.MaxPool2d(2))\n",
    "                ]\n",
    "            )\n",
    "        )\n",
    "        self.block2 = nn.Sequential(\n",
    "            OrderedDict(\n",
    "                [\n",
    "                    (\"dense1\",nn.Linear(32*3*3,128)),\n",
    "                    (\"relu_2\",nn.ReLU()),\n",
    "                    (\"dense2\",nn.Linear(128,10))\n",
    "                ]\n",
    "            )\n",
    "        )\n",
    "        \n",
    "    def forward(self,x):\n",
    "        conv_out2 = self.block(x)\n",
    "        res = conv_out2.view(conv_out2.size(0),-1)\n",
    "        out = self.block2(res)\n",
    "        return out\n",
    "net4 = Net4()\n",
    "print(net4)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('env1')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "bc8c60f99e2e962c0e4a3e9c9f27c1bb5f2a586f6d03b97348d9b6648bd2cf92"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
